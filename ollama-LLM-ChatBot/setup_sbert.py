#!/usr/bin/env python3
"""
SBERT ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì˜ë„ ë¶„ë¥˜ê¸°ì— í•„ìš”í•œ SBERT ëª¨ë¸ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def check_dependencies():
    """ì˜ì¡´ì„± í™•ì¸"""
    print("=" * 60)
    print("ğŸ” ì˜ì¡´ì„± í™•ì¸")
    print("=" * 60)
    
    required_packages = [
        "sentence_transformers",
        "torch",
        "transformers",
        "numpy",
        "sklearn"  # scikit-learnì˜ ì‹¤ì œ import ì´ë¦„
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package.replace("-", "_"))
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package} (ì„¤ì¹˜ í•„ìš”)")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâš ï¸ ë‹¤ìŒ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:")
        for package in missing_packages:
            if package == "sklearn":
                print(f"pip install scikit-learn")
            else:
                print(f"pip install {package}")
        return False
    else:
        print(f"\nâœ… ëª¨ë“  ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return True

def setup_sbert_models():
    """SBERT ëª¨ë¸ë“¤ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œ"""
    print("=" * 60)
    print("ğŸ¤– SBERT ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ì„¤ì •")
    print("=" * 60)
    
    try:
        # sentence-transformers ì„í¬íŠ¸
        from sentence_transformers import SentenceTransformer
        
        # ë‹¤ìš´ë¡œë“œí•  ëª¨ë¸ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
        models = [
            {
                "name": "í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸",
                "model_id": "jhgan/ko-sroberta-multitask",
                "description": "í•œêµ­ì–´ êµí†µ ë„ë©”ì¸ì— ìµœì í™”ëœ SBERT ëª¨ë¸",
                "priority": 1
            },
            {
                "name": "ë²”ìš© ëª¨ë¸ (ëŒ€ì•ˆ)",
                "model_id": "sentence-transformers/all-MiniLM-L6-v2",
                "description": "ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ë²”ìš© SBERT ëª¨ë¸",
                "priority": 2
            },
            {
                "name": "ë‹¤êµ­ì–´ ëª¨ë¸ (ëŒ€ì•ˆ)",
                "model_id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                "description": "ë‹¤êµ­ì–´ ì§€ì› SBERT ëª¨ë¸",
                "priority": 3
            }
        ]
        
        print(f"\nğŸ“¥ SBERT ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ì´ ì„±ê³µí•˜ë©´ ë‚˜ë¨¸ì§€ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
        
        primary_model_success = False
        
        for i, model_info in enumerate(models, 1):
            print(f"\n{i}/{len(models)}. {model_info['name']}")
            print(f"   ëª¨ë¸ ID: {model_info['model_id']}")
            print(f"   ì„¤ëª…: {model_info['description']}")
            
            try:
                print(f"   â³ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                model = SentenceTransformer(model_info['model_id'])
                print(f"   âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
                test_sentences = ["ì•ˆë…•í•˜ì„¸ìš”", "êµí†µëŸ‰ í™•ì¸"]
                embeddings = model.encode(test_sentences)
                print(f"   ğŸ§ª í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì„ë² ë”© í¬ê¸°: {embeddings.shape})")
                
                # í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ì´ ì„±ê³µí•˜ë©´ ë‚˜ë¨¸ì§€ëŠ” ê±´ë„ˆë›°ê¸°
                if model_info['priority'] == 1:
                    primary_model_success = True
                    print(f"   ğŸ¯ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì„±ê³µ!")
                    print(f"   âœ… ë‚˜ë¨¸ì§€ ëŒ€ì•ˆ ëª¨ë¸ë“¤ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
                    break
                
            except Exception as e:
                print(f"   âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                if model_info['priority'] == 1:
                    print(f"   âš ï¸ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì‹¤íŒ¨. ëŒ€ì•ˆ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                    continue
                else:
                    print(f"   âš ï¸ ì´ ëª¨ë¸ì€ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                    continue
        
        if primary_model_success:
            print(f"\nâœ… í•œêµ­ì–´ íŠ¹í™” SBERT ëª¨ë¸ ì„¤ì • ì™„ë£Œ!")
            print("ì´ì œ ì˜ë„ ë¶„ë¥˜ê¸°ì—ì„œ ìµœì í™”ëœ í•œêµ­ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            print(f"\nâš ï¸ í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            print("ëŒ€ì•ˆ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ í™•ì¸
        cache_dir = Path.home() / ".cache" / "torch" / "sentence_transformers"
        if cache_dir.exists():
            print(f"\nğŸ“ ëª¨ë¸ ìºì‹œ ìœ„ì¹˜: {cache_dir}")
            cache_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
            print(f"ğŸ“Š ìºì‹œ í¬ê¸°: {cache_size / (1024*1024):.1f} MB")
        
        return primary_model_success
        
    except ImportError:
        print("âŒ sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install sentence-transformers")
        return False
    except Exception as e:
        print(f"âŒ SBERT ëª¨ë¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def test_core_modules():
    """í•µì‹¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
    print(f"\n" + "=" * 60)
    print("ğŸ§ª í•µì‹¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        from core.query_router import QueryRouter
        from core.sql_element_extractor import SQLElementExtractor
        from core.answer_generator import AnswerGenerator
        
        print("í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ!")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        test_questions = [
            "êµí†µëŸ‰ì´ ê°€ì¥ ë§ì€ êµ¬ê°„ì€ ì–´ë””ì¸ê°€ìš”?",
            "IFRO ì‹œìŠ¤í…œì´ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì•ˆë…•í•˜ì„¸ìš”"
        ]
        
        print(f"\ní…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤:")
        for i, question in enumerate(test_questions, 1):
            print(f"{i}. {question}")
        
        print(f"\nëª¨ë“ˆ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸:")
        try:
            router = QueryRouter()
            print("âœ… QueryRouter ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"âŒ QueryRouter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        try:
            extractor = SQLElementExtractor()
            print("âœ… SQLElementExtractor ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"âŒ SQLElementExtractor ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        try:
            generator = AnswerGenerator()
            print("âœ… AnswerGenerator ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            print(f"âŒ AnswerGenerator ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        print("âœ… í•µì‹¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ í•µì‹¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ SBERT ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ì„¤ì • ì‹œì‘")
    
    # 1. ì˜ì¡´ì„± í™•ì¸
    if not check_dependencies():
        print("\nâŒ ì˜ì¡´ì„± ë¬¸ì œë¡œ ì¸í•´ ì„¤ì •ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return
    
    # 2. SBERT ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    if not setup_sbert_models():
        print("\nâŒ SBERT ëª¨ë¸ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 3. í•µì‹¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    if not test_core_modules():
        print("\nâŒ í•µì‹¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"\n" + "=" * 60)
    print("ğŸ‰ SBERT ëª¨ë¸ ì„¤ì • ì™„ë£Œ!")
    print("ì´ì œ ìµœì í™”ëœ ì±—ë´‡ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("=" * 60)

if __name__ == "__main__":
    main()
